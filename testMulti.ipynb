{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d65f421-9939-467c-ac17-0f86f1c5aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- ---------\n",
      "alembic                       1.8.0\n",
      "altair                        4.2.0\n",
      "anyio                         3.6.1\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "asttokens                     2.0.5\n",
      "async-generator               1.10\n",
      "attrs                         21.4.0\n",
      "Babel                         2.10.3\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "beautifulsoup4                4.11.1\n",
      "bleach                        5.0.1\n",
      "blinker                       1.4\n",
      "bokeh                         2.4.3\n",
      "Bottleneck                    1.3.5\n",
      "brotlipy                      0.7.0\n",
      "cached-property               1.5.2\n",
      "certifi                       2022.6.15\n",
      "certipy                       0.1.3\n",
      "cffi                          1.15.1\n",
      "charset-normalizer            2.1.0\n",
      "click                         8.1.3\n",
      "cloudpickle                   2.1.0\n",
      "colorama                      0.4.5\n",
      "conda                         4.13.0\n",
      "conda-package-handling        1.8.1\n",
      "cryptography                  37.0.2\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.30\n",
      "cytoolz                       0.11.2\n",
      "dask                          2022.6.1\n",
      "debugpy                       1.6.0\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "dill                          0.3.5.1\n",
      "distributed                   2022.6.1\n",
      "entrypoints                   0.4\n",
      "executing                     0.8.3\n",
      "fastjsonschema                2.15.3\n",
      "flit_core                     3.7.1\n",
      "fonttools                     4.33.3\n",
      "fsspec                        2022.5.0\n",
      "gmpy2                         2.1.2\n",
      "greenlet                      1.1.2\n",
      "h5py                          3.6.0\n",
      "HeapDict                      1.0.1\n",
      "idna                          3.3\n",
      "imagecodecs                   2022.2.22\n",
      "imageio                       2.19.3\n",
      "importlib-metadata            4.11.4\n",
      "importlib-resources           5.8.0\n",
      "ipykernel                     6.15.0\n",
      "ipympl                        0.9.1\n",
      "ipython                       8.4.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.7.1\n",
      "jedi                          0.18.1\n",
      "Jinja2                        3.1.2\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.5\n",
      "jsonschema                    4.6.1\n",
      "jupyter-client                7.3.4\n",
      "jupyter-core                  4.10.0\n",
      "jupyter-server                1.18.0\n",
      "jupyter-telemetry             0.1.0\n",
      "jupyterhub                    2.3.1\n",
      "jupyterlab                    3.4.3\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab-server             2.14.0\n",
      "jupyterlab-widgets            1.1.1\n",
      "kiwisolver                    1.4.3\n",
      "libmambapy                    0.24.0\n",
      "llvmlite                      0.38.1\n",
      "locket                        1.0.0\n",
      "lz4                           4.0.0\n",
      "Mako                          1.2.1\n",
      "mamba                         0.24.0\n",
      "MarkupSafe                    2.1.1\n",
      "matplotlib                    3.5.2\n",
      "matplotlib-inline             0.1.3\n",
      "mistune                       0.8.4\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.4\n",
      "munkres                       1.1.4\n",
      "nbclassic                     0.3.7\n",
      "nbclient                      0.6.6\n",
      "nbconvert                     6.5.0\n",
      "nbformat                      5.4.0\n",
      "nest-asyncio                  1.5.5\n",
      "networkx                      2.8.4\n",
      "notebook                      6.4.12\n",
      "notebook-shim                 0.1.0\n",
      "numba                         0.55.2\n",
      "numexpr                       2.8.0\n",
      "numpy                         1.22.4\n",
      "oauthlib                      3.2.0\n",
      "packaging                     21.3\n",
      "pamela                        1.0.0\n",
      "pandas                        1.4.3\n",
      "pandocfilters                 1.5.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "patsy                         0.5.2\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.2.0\n",
      "pip                           22.1.2\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.30\n",
      "protobuf                      3.20.1\n",
      "psutil                        5.9.1\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "pyarrow                       8.0.0\n",
      "pycosat                       0.6.3\n",
      "pycparser                     2.21\n",
      "pycurl                        7.45.1\n",
      "Pygments                      2.12.0\n",
      "PyJWT                         2.4.0\n",
      "pyOpenSSL                     22.0.0\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.18.1\n",
      "PySocks                       1.7.1\n",
      "pyspark                       3.2.1\n",
      "python-dateutil               2.8.2\n",
      "python-json-logger            2.0.1\n",
      "pytz                          2022.1\n",
      "PyWavelets                    1.3.0\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "requests                      2.28.1\n",
      "ruamel.yaml                   0.17.21\n",
      "ruamel.yaml.clib              0.2.6\n",
      "ruamel-yaml-conda             0.15.80\n",
      "scikit-image                  0.19.3\n",
      "scikit-learn                  1.1.1\n",
      "scipy                         1.8.1\n",
      "seaborn                       0.11.2\n",
      "Send2Trash                    1.8.0\n",
      "setuptools                    63.1.0\n",
      "six                           1.16.0\n",
      "sniffio                       1.2.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.1\n",
      "SQLAlchemy                    1.4.39\n",
      "stack-data                    0.3.0\n",
      "statsmodels                   0.13.2\n",
      "sympy                         1.10.1\n",
      "tableauserverclient           0.23\n",
      "tables                        3.7.0\n",
      "tblib                         1.7.0\n",
      "teams-logger                  0.4.1\n",
      "terminado                     0.15.0\n",
      "threadpoolctl                 3.1.0\n",
      "tifffile                      2022.5.4\n",
      "tinycss2                      1.1.1\n",
      "toolz                         0.11.2\n",
      "tornado                       6.2\n",
      "tqdm                          4.64.0\n",
      "traitlets                     5.3.0\n",
      "typing_extensions             4.3.0\n",
      "unicodedata2                  14.0.0\n",
      "urllib3                       1.26.9\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              1.3.3\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.6.1\n",
      "xlrd                          2.0.1\n",
      "zict                          2.2.0\n",
      "zipp                          3.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f7cea5-5c44-4fe2-ba93-0134666eca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session & context\n",
    "spark = SparkSession \\\n",
    "  .builder \\\n",
    "  .appName(\"multi key test\") \\\n",
    "  .master(\"local[2]\") \\\n",
    "  .getOrCreate()\n",
    "\n",
    "sc= spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa013914-2626-440e-951c-97f20005a698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000000050000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of the first 100 Whole numbers\n",
    "rdd = sc.parallelize(range(100000000 +1))\n",
    "rdd.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9100e17a-6362-454b-bc80-f7c88b790402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.32543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.431</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8125</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>15.39</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.16760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>6.426</td>\n",
       "      <td>52.3</td>\n",
       "      <td>4.5404</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.20</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.07875</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.782</td>\n",
       "      <td>41.1</td>\n",
       "      <td>3.7886</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>393.87</td>\n",
       "      <td>6.68</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.04666</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404</td>\n",
       "      <td>7.107</td>\n",
       "      <td>36.6</td>\n",
       "      <td>7.3090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>354.31</td>\n",
       "      <td>8.61</td>\n",
       "      <td>30.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.25356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.705</td>\n",
       "      <td>77.7</td>\n",
       "      <td>3.9450</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>396.42</td>\n",
       "      <td>11.50</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "128  0.32543   0.0  21.89   0.0  0.624  6.431  98.8  1.8125  4.0  437.0   \n",
       "320  0.16760   0.0   7.38   0.0  0.493  6.426  52.3  4.5404  5.0  287.0   \n",
       "187  0.07875  45.0   3.44   0.0  0.437  6.782  41.1  3.7886  5.0  398.0   \n",
       "197  0.04666  80.0   1.52   0.0  0.404  7.107  36.6  7.3090  2.0  329.0   \n",
       "315  0.25356   0.0   9.90   0.0  0.544  5.705  77.7  3.9450  4.0  304.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "128     21.2  396.90  15.39    18.0  \n",
       "320     19.6  396.90   7.20    23.8  \n",
       "187     15.2  393.87   6.68    32.0  \n",
       "197     12.6  354.31   8.61    30.3  \n",
       "315     18.4  396.42  11.50    16.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load the boston data set\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "# convert to a Pandas Data Frame\n",
    "boston_pd = pd.DataFrame(data= np.c_[boston['data'],boston['target']], \n",
    "              columns= np.append(boston['feature_names'], 'target')).sample(frac=1)\n",
    "print(boston_pd.shape)\n",
    "boston_pd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0561e11-1ec9-4cc5-b3b6-831217930328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-sqaured: 0.7600288746579493\n",
      "MAE: 3.073334194582059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# split into data and label arrays \n",
    "y = boston_pd['target']\n",
    "X = boston_pd.drop(['target'], axis=1)\n",
    "\n",
    "# create training (~80%) and test data sets\n",
    "X_train = X[:400]\n",
    "X_test = X[400:]\n",
    "y_train = y[:400]\n",
    "y_test = y[400:]\n",
    "\n",
    "# train a classifier \n",
    "lr = LinearRegression()\n",
    "model = lr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# error metrics\n",
    "r = pearsonr(y_pred, y_test)\n",
    "mae = sum(abs(y_pred - y_test))/len(y_test)\n",
    "print(\"R-sqaured: \" + str(r[0]**2))\n",
    "print(\"MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c155266-c6e4-4580-b718-ec41f8f56bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CRIM=0.32543, ZN=0.0, INDUS=21.89, CHAS=0.0, NOX=0.624, RM=6.431, AGE=98.8, DIS=1.8125, RAD=4.0, TAX=437.0, PTRATIO=21.2, B=396.9, LSTAT=15.39, target=18.0),\n",
       " Row(CRIM=0.1676, ZN=0.0, INDUS=7.38, CHAS=0.0, NOX=0.493, RM=6.426, AGE=52.3, DIS=4.5404, RAD=5.0, TAX=287.0, PTRATIO=19.6, B=396.9, LSTAT=7.2, target=23.8),\n",
       " Row(CRIM=0.07875, ZN=45.0, INDUS=3.44, CHAS=0.0, NOX=0.437, RM=6.782, AGE=41.1, DIS=3.7886, RAD=5.0, TAX=398.0, PTRATIO=15.2, B=393.87, LSTAT=6.68, target=32.0),\n",
       " Row(CRIM=0.04666, ZN=80.0, INDUS=1.52, CHAS=0.0, NOX=0.404, RM=7.107, AGE=36.6, DIS=7.309, RAD=2.0, TAX=329.0, PTRATIO=12.6, B=354.31, LSTAT=8.61, target=30.3),\n",
       " Row(CRIM=0.25356, ZN=0.0, INDUS=9.9, CHAS=0.0, NOX=0.544, RM=5.705, AGE=77.7, DIS=3.945, RAD=4.0, TAX=304.0, PTRATIO=18.4, B=396.42, LSTAT=11.5, target=16.2)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([0.3254, 0.0, 21.89, 0.0, 0.624, 6.431, 98.8, 1.8125, 4.0, 437.0, 21.2, 396.9, 15.39]), target=18.0),\n",
       " Row(features=DenseVector([0.1676, 0.0, 7.38, 0.0, 0.493, 6.426, 52.3, 4.5404, 5.0, 287.0, 19.6, 396.9, 7.2]), target=23.8),\n",
       " Row(features=DenseVector([0.0788, 45.0, 3.44, 0.0, 0.437, 6.782, 41.1, 3.7886, 5.0, 398.0, 15.2, 393.87, 6.68]), target=32.0),\n",
       " Row(features=DenseVector([0.0467, 80.0, 1.52, 0.0, 0.404, 7.107, 36.6, 7.309, 2.0, 329.0, 12.6, 354.31, 8.61]), target=30.3),\n",
       " Row(features=DenseVector([0.2536, 0.0, 9.9, 0.0, 0.544, 5.705, 77.7, 3.945, 4.0, 304.0, 18.4, 396.42, 11.5]), target=16.2)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# convert to a Spark data frame\n",
    "boston_sp = spark.createDataFrame(boston_pd)\n",
    "display(boston_sp.take(5))\n",
    "\n",
    "# split into training and test spark data frames\n",
    "boston_train = spark.createDataFrame(boston_pd[:400])\n",
    "boston_test = spark.createDataFrame(boston_pd[400:])\n",
    "\n",
    "# convert to vector representation for MLlib\n",
    "assembler = VectorAssembler(inputCols= boston_train.schema.names[:(boston_pd.shape[1] - 1)],  \n",
    "                                                                        outputCol=\"features\" )\n",
    "boston_train = assembler.transform(boston_train).select('features', 'target') \n",
    "boston_test = assembler.transform(boston_test).select('features', 'target') \n",
    "\n",
    "display(boston_train.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c19fb2-44b4-4dbe-8d57-f41ac1a964db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-sqaured: 0.7461414801327885\n"
     ]
    }
   ],
   "source": [
    "# linear regresion with Spark\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# linear regression \n",
    "lr = LinearRegression(maxIter=10, regParam=0.1, \n",
    "                      elasticNetParam=0.5, labelCol=\"target\")\n",
    "\n",
    "# Fit the model\n",
    "model = lr.fit(boston_train)\n",
    "boston_pred = model.transform(boston_test)\n",
    "\n",
    "# calculate results \n",
    "r = boston_pred.stat.corr(\"prediction\", \"target\")\n",
    "print(\"R-sqaured: \" + str(r**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d2be78-d504-4abd-8694-01996e0d3c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-sqaured: 0.7600288746579517\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "crossval = CrossValidator(estimator=LinearRegression(labelCol = \"target\"),  \n",
    "                         estimatorParamMaps=ParamGridBuilder().addGrid(\n",
    "                           LinearRegression.elasticNetParam, [0, 0.5, 1.0]).build(),\n",
    "                         evaluator=RegressionEvaluator(\n",
    "                           labelCol = \"target\", metricName = \"r2\"),\n",
    "                         numFolds=10)\n",
    "\n",
    "# cross validate the model and select the best fit\n",
    "cvModel = crossval.fit(boston_train) \n",
    "model = cvModel.bestModel\n",
    "\n",
    "# calculate results \n",
    "boston_pred = model.transform(boston_test)\n",
    "r = boston_pred.stat.corr(\"prediction\", \"target\")\n",
    "print(\"R-sqaured: \" + str(r**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c34d105e-af49-4c1e-b962-3b823c8113d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 0.786279363847181], [20, 0.8170691225800597], [50, 0.7997018115080141]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn version \n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# allow up to 5 concurrent threads\n",
    "pool = ThreadPool(5)\n",
    "\n",
    "# hyperparameters to test out (n_trees)\n",
    "parameters = [ 10, 20, 50]\n",
    "\n",
    "# define a function to train a RF model and return metrics \n",
    "def sklearn_random_forest(trees, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # train a random forest regressor with the specified number of trees\n",
    "    rf= RFR(n_estimators = trees)\n",
    "    model = rf.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    r = pearsonr(y_pred, y_test)\n",
    "\n",
    "    # return the number of trees, and the R value \n",
    "    return [trees, r[0]**2]  \n",
    "\n",
    "# run the tasks \n",
    "pool.map(lambda trees: sklearn_random_forest(trees, X_train,\n",
    "                                           X_test, y_train, y_test), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf70adbd-df4a-4c17-a430-815486431ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 0.842436670938509], [20, 0.8993035953885388], [50, 0.8723947471442912]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark version\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# define a function to train a RF model and return metrics \n",
    "def mllib_random_forest(trees, boston_train, boston_test):\n",
    "\n",
    "    # train a random forest regressor with the specified number of trees\n",
    "    rf = RandomForestRegressor(numTrees = trees, labelCol=\"target\")\n",
    "    model = rf.fit(boston_train)\n",
    "\n",
    "    # make predictions\n",
    "    boston_pred = model.transform(boston_test)\n",
    "    r = boston_pred.stat.corr(\"prediction\", \"target\")\n",
    "\n",
    "    # return the number of trees, and the R value \n",
    "    return [trees, r**2]\n",
    "  \n",
    "# run the tasks \n",
    "pool.map(lambda trees: mllib_random_forest(trees, boston_train, boston_test), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7e8110-8e1c-4e96-98d9-e133e69a519a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|trees|         r_squared|\n",
      "+-----+------------------+\n",
      "|   11| 0.915390018129497|\n",
      "|   20|0.9059665054820668|\n",
      "|   50| 0.912715138678595|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# setup the spark data frame as a table\n",
    "boston_sp.createOrReplaceTempView(\"boston\")\n",
    "\n",
    "# add train/test label and expand the data set by 3x (each num trees parameter)\n",
    "full_df = spark.sql(\"\"\"\n",
    "  select *\n",
    "  from (\n",
    "    select *, case when rand() < 0.8 then 1 else 0 end as training \n",
    "    from boston\n",
    "  ) b\n",
    "  cross join (\n",
    "      select 11 as trees union all select 20 as trees union all select 50 as trees)\n",
    "\"\"\")\n",
    "\n",
    "schema = StructType([StructField('trees', LongType(), True),\n",
    "                     StructField('r_squared', DoubleType(), True)])  \n",
    "\n",
    "#@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def train_RF(boston_pd):\n",
    "    trees = boston_pd['trees'].unique()[0]\n",
    "\n",
    "    # get the train and test groups \n",
    "    boston_train = boston_pd[boston_pd['training'] == 1]\n",
    "    boston_test = boston_pd[boston_pd['training'] == 0] \n",
    "        \n",
    "    # create data and label groups \n",
    "    y_train = boston_train['target']\n",
    "    X_train = boston_train.drop(['target'], axis=1)\n",
    "    y_test = boston_test['target']\n",
    "    X_test = boston_test.drop(['target'], axis=1)\n",
    "   \n",
    "    # train a classifier \n",
    "    rf= RFR(n_estimators = trees)\n",
    "    model = rf.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    r = pearsonr(y_pred, y_test)\n",
    "    \n",
    "    # return the number of trees, and the R value \n",
    "    return pd.DataFrame({'trees': trees, 'r_squared': (r[0]**2)}, index=[0])\n",
    "  \n",
    "# use the Pandas UDF\n",
    "# results = full_df.groupby('trees').apply(train_RF)\n",
    "\n",
    "# print the results \n",
    "# print(results.take(3))\n",
    "\n",
    "full_df.groupby('trees').applyInPandas(\n",
    "    train_RF, schema=\"trees long, r_squared double\").show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb150d7-2119-4fab-bcdb-fd1f9a47891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|                  v|\n",
      "+---+-------------------+\n",
      "|  1|-0.7071067811865475|\n",
      "|  1| 0.7071067811865475|\n",
      "|  2|-0.8320502943378437|\n",
      "|  2|-0.2773500981126146|\n",
      "|  2| 1.1094003924504583|\n",
      "+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from pyspark.sql.functions import pandas_udf, ceil\n",
    "df = spark.createDataFrame(\n",
    "    [(1, 1.0), (1, 2.0), (2, 3.0), (2, 5.0), (2, 10.0)],\n",
    "    (\"id\", \"v\"))  \n",
    "def normalize(pdf):\n",
    "    v = pdf.v\n",
    "    return pdf.assign(v=(v - v.mean()) / v.std())\n",
    "df.groupby(\"id\").applyInPandas(\n",
    "    normalize, schema=\"id long, v double\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c80775-5091-44f8-9519-a783b4fbba8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
